{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1tZGLO67kFJXHxonR1Kc0XyJuNbXUXk93",
      "authorship_tag": "ABX9TyPn5hG9wQpB6FjTuM7vTS1l"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Seq2seq 시퀀스-투-시퀀스 모델링 작업\n",
        "- 문자 수준의 텍스트 생성 RNN -LSTM 모델 이용\n",
        "- '머신러닝 교과서 개정3판 p705' 참고\n",
        "\n",
        "### 1. 텍스트 데이터셋 확보\n"
      ],
      "metadata": {
        "id": "dkvYnHyvwTAj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "vBMfb0CgS15q",
        "outputId": "050f0131-8553-458d-a3cf-c88e816fb9d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The Project Gutenberg eBook, Grimm's Fairy Stories, by Jacob Grimm and\\nWilhelm Grimm, Illustrated by John B Gruelle and R. Emmett Owen\\n\\n\\nThis eBook is for the use of anyone anywhere at no cost and with\\nalmost no restrictions whatsoever.  You may copy it, give it away or\\nre-use it under the terms of the Project Gutenberg License included\\nwith this eBook or online at www.gutenberg.org\\n\\n\\n\\n\\n\\nTitle: Gr\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 데이터셋: https://www.gutenberg.org/files/11027/11027.txt (그림형제 요정 동화)\n",
        "# 텍스트 읽고 전처리하기\n",
        "with open(\"/content/drive/MyDrive/11027.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "  text = f.read()\n",
        "\n",
        "text[:400]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_idx = text.find('THE GOOSE-GIRL')\n",
        "end_idx = text.find('END OF THE PROJECT GUTENBERG')\n",
        "text = text[start_idx:end_idx]\n",
        "char_set = set(text)\n",
        "print('전체 길이:', len(text))\n",
        "print('고유 문자:', len(char_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2SrOfRFTkA4",
        "outputId": "0e9667a3-f0f5-4574-8af7-234714141ef2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 길이: 266073\n",
            "고유 문자: 70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text[:14]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zeHQyCkwWOm9",
        "outputId": "8314a92d-2f61-48a9-9a20-1876abef0d55"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'THE GOOSE-GIRL'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 정수 인코딩 & 넘파일 배열을 활용한 역매핑\n",
        "\n",
        "chars_sorted = sorted(char_set)\n",
        "char2int = {ch:i for i, ch in enumerate(chars_sorted)}\n",
        "char_array = np.array(chars_sorted)\n",
        "\n",
        "text_encoded = np.array([char2int[ch] for ch in text], dtype=np.int32)\n",
        "print('인코딩 된 텍스트 크기:', text_encoded.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bt69pPtUS2r",
        "outputId": "0222fde6-610e-4270-887e-0c2c2c2db4ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코딩 된 텍스트 크기: (266073,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:14], ' ====인코딩===> ', text_encoded[:14])\n",
        "print(text_encoded[14:46], ' ===디코딩===> ', ''.join(char_array[text_encoded][14:46]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euidiSoMXGym",
        "outputId": "e4798e6b-540c-45aa-bba4-0de5a0705435"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THE GOOSE-GIRL  ====인코딩===>  [34 22 19  1 21 29 29 33 19  9 21 23 32 26]\n",
            "[ 0  0 34 22 19  1 26 23 34 34 26 19  1 16 32 29 34 22 19 32  1 15 28 18\n",
            "  1 33 23 33 34 19 32  0]  ===디코딩===>  \n",
            "\n",
            "THE LITTLE BROTHER AND SISTER\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 텐서플로우로 데이터셋 만들기"
      ],
      "metadata": {
        "id": "tKhaB1NYYLiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# 텍스트 순서대로 인코딩 저장\n",
        "ds_text_encoded = tf.data.Dataset.from_tensor_slices(text_encoded)\n",
        "\n",
        "for ex in ds_text_encoded.take(5):\n",
        "  print('{} -> {}'.format(ex.numpy(), char_array[ex.numpy()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOrNU-1TXb1b",
        "outputId": "53bb7b72-2a70-40b7-bd28-7c4e74973e5d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34 -> T\n",
            "22 -> H\n",
            "19 -> E\n",
            "1 ->  \n",
            "21 -> G\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bath() 이용하여 텍스트 조각 만들기\n",
        "\n",
        "seq_length = 50 # 변경 가능\n",
        "chunk_size = seq_length + 1\n",
        "ds_chunks = ds_text_encoded.batch(chunk_size, drop_remainder=True)\n",
        "\n",
        "# x, y를 나누기 위한 함수 정의\n",
        "\n",
        "def split_input_target(chunk):\n",
        "  input_seq = chunk[:-1]\n",
        "  target_seq = chunk[1:]\n",
        "  return input_seq, target_seq\n",
        "\n",
        "ds_sequences = ds_chunks.map(split_input_target) # 모든 조각에 적용하기\n",
        "\n",
        "# 데이터셋에서 샘플 확인\n",
        "\n",
        "for example in ds_sequences.take(2):\n",
        "  print('입력 x: ', repr(''.join(char_array[example[0].numpy()])))\n",
        "  print('타깃 y: ', repr(''.join(char_array[example[1].numpy()])))\n",
        "  print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8ySwAW4Yvi8",
        "outputId": "69c8d582-50b9-42e2-8951-fe200f1aa928"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 x:  'THE GOOSE-GIRL\\n\\nTHE LITTLE BROTHER AND SISTER\\n\\nHAN'\n",
            "타깃 y:  'HE GOOSE-GIRL\\n\\nTHE LITTLE BROTHER AND SISTER\\n\\nHANS'\n",
            "\n",
            "입력 x:  'EL AND GRETHEL\\n\\nOH, IF I COULD BUT SHIVER!\\n\\nDUMMLI'\n",
            "타깃 y:  'L AND GRETHEL\\n\\nOH, IF I COULD BUT SHIVER!\\n\\nDUMMLIN'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 미니 배치로 나누기 (여러 개의 훈련 샘플을 갖고 있음)\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "ds = ds_sequences.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "L4mVLFOWaeND"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. RNN 모델 만들기"
      ],
      "metadata": {
        "id": "SCtmn9qKa7aY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의 (함수 사용)\n",
        "\n",
        "def build_model(vocab_size, embedding_dim, rnn_units):\n",
        "  model= tf.keras.Sequential([\n",
        "      tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
        "      tf.keras.layers.LSTM(\n",
        "          rnn_units,\n",
        "          return_sequences = True),\n",
        "          tf.keras.layers.Dense(vocab_size)])\n",
        "  \n",
        "  return model\n",
        "\n",
        "# 매개변수 설정\n",
        "\n",
        "charset_size = len(char_array)\n",
        "embedding_dim= 256\n",
        "rnn_units = 512\n",
        "\n",
        "tf.random.set_seed(1)\n",
        "model = build_model(\n",
        "    vocab_size = charset_size,\n",
        "    embedding_dim = embedding_dim,\n",
        "    rnn_units = rnn_units\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# LSTM 출력크기 (None, None, 256) 랭크 3 -> 이유: LSTM 만들때 return_sequences=True로 지정했기 때문\n",
        "# 완전 연결층 (Dense)이 LSTM 출력을 받아 출력 시퀀스의 각 원소마다 로짓을 계산\n",
        "# 순서대로 배치 차원, 출력 시퀀스 길이, 은닉 유닛 개수"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQzif8ZOa5kA",
        "outputId": "37d40e21-c395-4005-9710-af9fa744b8c5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 256)         17920     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, None, 512)         1574912   \n",
            "                                                                 \n",
            " dense (Dense)               (None, None, 70)          35910     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,628,742\n",
            "Trainable params: 1,628,742\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 학습"
      ],
      "metadata": {
        "id": "VjnVnWbgfY9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='Adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True\n",
        "    )\n",
        ")\n",
        "\n",
        "# from_logits=True: 새로운 텍스트를 생성하기 위해 모델 예측값에서 샘플링 할 수 있도록 로짓 출력값이 필요\n",
        "# activation=None\n",
        "\n",
        "model.fit(ds, epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7RTPF4hbCZx",
        "outputId": "d18f1314-7625-4fbc-9893-4db37f59a9ac"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "82/82 [==============================] - 8s 15ms/step - loss: 2.9678\n",
            "Epoch 2/20\n",
            "82/82 [==============================] - 1s 14ms/step - loss: 2.2996\n",
            "Epoch 3/20\n",
            "82/82 [==============================] - 1s 14ms/step - loss: 2.0773\n",
            "Epoch 4/20\n",
            "82/82 [==============================] - 1s 14ms/step - loss: 1.9225\n",
            "Epoch 5/20\n",
            "82/82 [==============================] - 1s 14ms/step - loss: 1.8030\n",
            "Epoch 6/20\n",
            "82/82 [==============================] - 1s 13ms/step - loss: 1.7069\n",
            "Epoch 7/20\n",
            "82/82 [==============================] - 1s 14ms/step - loss: 1.6286\n",
            "Epoch 8/20\n",
            "82/82 [==============================] - 1s 13ms/step - loss: 1.5626\n",
            "Epoch 9/20\n",
            "82/82 [==============================] - 1s 14ms/step - loss: 1.5076\n",
            "Epoch 10/20\n",
            "82/82 [==============================] - 1s 14ms/step - loss: 1.4590\n",
            "Epoch 11/20\n",
            "82/82 [==============================] - 1s 14ms/step - loss: 1.4158\n",
            "Epoch 12/20\n",
            "82/82 [==============================] - 1s 13ms/step - loss: 1.3789\n",
            "Epoch 13/20\n",
            "82/82 [==============================] - 1s 14ms/step - loss: 1.3429\n",
            "Epoch 14/20\n",
            "82/82 [==============================] - 1s 14ms/step - loss: 1.3118\n",
            "Epoch 15/20\n",
            "82/82 [==============================] - 1s 14ms/step - loss: 1.2823\n",
            "Epoch 16/20\n",
            "82/82 [==============================] - 1s 14ms/step - loss: 1.2536\n",
            "Epoch 17/20\n",
            "82/82 [==============================] - 1s 14ms/step - loss: 1.2270\n",
            "Epoch 18/20\n",
            "82/82 [==============================] - 1s 14ms/step - loss: 1.2000\n",
            "Epoch 19/20\n",
            "82/82 [==============================] - 1s 14ms/step - loss: 1.1744\n",
            "Epoch 20/20\n",
            "82/82 [==============================] - 1s 14ms/step - loss: 1.1505\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f94602a24d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 평가: 새로운 텍스트 생성하기"
      ],
      "metadata": {
        "id": "YmXtlF8tp5ZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(model, starting_str,\n",
        "           len_generated_text=500,\n",
        "           max_input_length=50,\n",
        "           scale_factor=1.0):\n",
        "  encoded_input = [char2int[s] for s in starting_str]\n",
        "  encoded_input = tf.reshape(encoded_input, (1, -1))\n",
        "\n",
        "  generated_str = starting_str\n",
        "\n",
        "  model.reset_states\n",
        "\n",
        "  for i in range(len_generated_text):\n",
        "    logits = model(encoded_input)\n",
        "    logits = tf.squeeze(logits, 0)\n",
        "\n",
        "    scaled_logits = logits * scale_factor\n",
        "    new_char_indx = tf.random.categorical(\n",
        "        scaled_logits, num_samples=1)\n",
        "\n",
        "    new_char_indx = tf.squeeze(new_char_indx)[-1].numpy()\n",
        "\n",
        "    generated_str += str(char_array[new_char_indx])\n",
        "\n",
        "    new_char_indx = tf.expand_dims([new_char_indx], 0)\n",
        "    encoded_input = tf.concat([encoded_input, new_char_indx], axis=1)\n",
        "    encdoed_input = encoded_input[:, -max_input_length:]\n",
        "\n",
        "    \n",
        "  return generated_str\n",
        "\n",
        "tf.random.set_seed(1)\n",
        "print(sample(model, starting_str='Grimm Brothers'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qISpPRuqf9x0",
        "outputId": "8c39cc10-b0bf-4e27-ef72-a997b0894c17"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grimm Brothers behild, and then came\n",
            "towards; for\n",
            "asked her boud\n",
            "and one sat discovered to open, and kepping toward a paugh stranger pior, and bofred at him\n",
            "round them, sent a bit blow. I shat her sut off this younger man understuning that it grinding before,\n",
            "they went all to forest! I will not get deward\" saking of a fine, but he took her and feathers, but they called out works into the lazeest meant she had mother,\n",
            "when they deppinayed nothing in the old of hunger, but only heard her,\n",
            "another\n",
            "our cheeses up\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**샘플 예측 가능성 (Randomness) 조절**\n",
        "- 생성된 텍스트가 훈련 테스트에서 학습한 패턴을 따르게 할지,\n",
        "- 랜덤하게 생성할지 조절하기 위해 RNN이 계산한 로짓을 tf.random.categorical()\n",
        " - 샘플링 함수로 전달 하기 전 *ɑ* 알파로 스케일 조정가능\n",
        " - 온도의 역수ɑ: 높을수록 무작위성 커지고, 낮을 수록 예측가능"
      ],
      "metadata": {
        "id": "mjeSaqI_oxPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예시, ɑ < 1로 로짓 스케일을 조정하면 softmax 함수가 계산할 확률은\n",
        "# 다음과 코드처럼 더 균일해짐\n",
        "\n",
        "logits = np.array([1.0, 1.0, 3.0])\n",
        "print('스케일 조정 전의 확률: ', tf.math.softmax(logits).numpy())\n",
        "print('0.5배 조정 후 확률: ', tf.math.softmax(0.5*logits).numpy())\n",
        "print('0.1배 조정 후 확률: ', tf.math.softmax(0.1*logits).numpy())\n"
      ],
      "metadata": {
        "id": "QV972JO8sE1G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6596a291-9a32-43df-efb1-6c39b17e5f8e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "스케일 조정 전의 확률:  [0.10650698 0.10650698 0.78698604]\n",
            "0.5배 조정 후 확률:  [0.21194156 0.21194156 0.57611688]\n",
            "0.1배 조정 후 확률:  [0.31042377 0.31042377 0.37915245]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ɑ=0.1로 스케일을 조정하면 거의 균등한 확률을 얻음\n",
        "- 균등한 분포일수록 더 랜덤하게 샘플링"
      ],
      "metadata": {
        "id": "ulGBfsq7rqyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 생성에 적용\n",
        "\n",
        "tf.random.set_seed(1)\n",
        "print(sample(model, starting_str='THE GOOSE-GIRL',\n",
        "             scale_factor=2.0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YL4ttRhPqikv",
        "outputId": "fbe672fe-a97f-49a8-994d-64bb2ef27170"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THE GOOSE-GIRL\n",
            "\n",
            "\n",
            "Once upon a time conding to go to the beautiful clothes, and it heard they were not be into the house. She stood a fine disappeared, and the bridd bring and went to the faithful John, and they went out of the castle, and was a great feather. The King all was from the heak of the words and heard themself began to the true trees and went to the forest to cellect for them. The terthing took their dear bride, and cried out, \"Who you will learn have no one mount to cold her, and asked them as so m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(1)\n",
        "print(sample(model, starting_str='THE GOOSE-GIRL',\n",
        "             scale_factor=0.5))\n",
        "\n",
        "# ɑ=0.5로 온도를 높이면 더 랜덤한 텍스트 생성되는 것을 확인가능"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTcWrKRYsFJf",
        "outputId": "2e5153b8-0c27-4bc7-d5d5-3b1dfa2861ac"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THE GOOSE-GIRLT\n",
            "\n",
            "OAlo: Tase, Snoccencurmah\n",
            "Tumf axarness,\n",
            "you yausE\"; but Hankit?\"\n",
            "Then then, stxnuck suct*man wihe after\n",
            "youghad you; orewhort\n",
            "of: Keptinrabr, wed iptabse!\" \"Mying Wom.\"\n",
            " Then her lutgesmening.\n",
            "\"Younrymanlubred, upon a: lyiZ hargly\n",
            "Rashee,\".\n",
            "\n",
            "So Once more t off.\n",
            "Sow! We knew I knepld\"; finh!\n",
            "  THee; arful Firg ame.\n",
            "It squck hexe; I wil, boAl\n",
            "Cared dim nom ye;\n",
            "bebir,\n",
            "ant ilow!e's mace, she haismyt,\n",
            "\"Caw!\n",
            "take Pell!,\")ay, and tyen is qulenir own, Ofewht.\" HorWhe's dwilld,\n",
            "Oho! Ropou.\"\n",
            "\n",
            "Thenself\n"
          ]
        }
      ]
    }
  ]
}